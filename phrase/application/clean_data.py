# -*- coding: utf-8 -*-
# dj/phrase/application/clean_data.py
"""
playphrase.me ë°ì´í„° ì •ë¦¬ ë° ì¶”ì¶œ ëª¨ë“ˆ - 4ê°œ ëª¨ë“ˆ ì™„ì „ ìµœì í™”
- models.py, managers.py, views.py, get_movie_info.pyì™€ ì™„ë²½ ì—°ë™
- ìƒˆë¡œìš´ ëª¨ë¸ êµ¬ì¡°ì— ë§ì¶˜ ë°ì´í„° ì¶”ì¶œ
- ë§¤ë‹ˆì €ë¥¼ í™œìš©í•œ íš¨ìœ¨ì ì¸ ì¤‘ë³µ ê²€ì‚¬
- ìºì‹± ì‹œìŠ¤í…œ í†µí•© ë° ì„±ëŠ¥ ìµœì í™”
"""
import re
import json
import logging
from django.core.cache import cache
from django.db import transaction, models
from django.utils import timezone
from phrase.models import MovieTable, DialogueTable, RequestTable
from phrase.application.get_imdb_poster_url import get_poster_url, download_poster_image

logger = logging.getLogger(__name__)

# ===== ê¸°ë³¸ ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ë“¤ =====

def decode_playphrase_format(text):
    """
    playphrase.meì˜ íŠ¹ìˆ˜ ì¸ì½”ë”©ì„ í‘œì¤€ JSONìœ¼ë¡œ ë³€í™˜
    Â° -> {, Ã§ -> }, Â¡ -> [, Â¿ -> ]
    """
    if not text:
        return ""
    
    # ìºì‹œ í™•ì¸ (ì¸ì½”ë”© ê²°ê³¼)
    cache_key = f"decoded_{hash(text[:100])}"
    cached_result = cache.get(cache_key)
    
    if cached_result:
        logger.debug("ë””ì½”ë”© ê²°ê³¼ ìºì‹œì—ì„œ ì¡°íšŒ")
        return cached_result
    
    # íŠ¹ìˆ˜ ë¬¸ìë¥¼ JSON í‘œì¤€ ë¬¸ìë¡œ ë³€í™˜
    text = text.replace('Â°', '{')
    text = text.replace('Ã§', '}')
    text = text.replace('Â¡', '[')
    text = text.replace('Â¿', ']')
    
    # ì‘ì€ë”°ì˜´í‘œë¥¼ í°ë”°ì˜´í‘œë¡œ ë³€í™˜ (JSON í‘œì¤€)
    text = re.sub(r"'([^']*?)':", r'"\1":', text)
    text = re.sub(r": '([^']*?)'([,}\]])", r': "\1"\2', text)
    text = re.sub(r"\['([^']*?)'\]", r'["\1"]', text)
    text = re.sub(r", '([^']*?)'([,\]])", r', "\1"\2', text)
    
    # ìºì‹œì— ì €ì¥ (1ì‹œê°„)
    cache.set(cache_key, text, 3600)
    
    return text


def extract_movie_info(data_text):
    """
    playphrase.me ë°ì´í„°ì—ì„œ ì˜í™” ì •ë³´ ì¶”ì¶œ (ìµœì í™”)
    
    ê°œì„ ì‚¬í•­:
    - ìƒˆ ëª¨ë¸ êµ¬ì¡°ì— ë§ì¶˜ í•„ë“œ ë§¤í•‘
    - ì¤‘ë³µ ê²€ì‚¬ ìµœì í™”
    - ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
    - ìºì‹± ì ìš©
    """
    if not data_text:
        logger.warning("ì…ë ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    if not isinstance(data_text, str):
        logger.error(f"ì˜ëª»ëœ ë°ì´í„° íƒ€ì…: {type(data_text)}")
        return []
    
    # ìºì‹œ í™•ì¸ (ì¶”ì¶œ ê²°ê³¼)
    cache_key = f"extracted_movies_{hash(data_text)}"
    cached_result = cache.get(cache_key)
    
    if cached_result:
        logger.info(f"ì˜í™” ì •ë³´ ìºì‹œì—ì„œ ì¡°íšŒ: {len(cached_result)}ê°œ")
        return cached_result
    
    try:
        # ë°ì´í„° ë””ì½”ë”©
        decoded_text = decode_playphrase_format(data_text)
        
        if not decoded_text.strip():
            logger.warning("ë””ì½”ë”©ëœ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return []
        
        # JSON íŒŒì‹±ì„ ìœ„í•œ ì¶”ê°€ ì •ë¦¬
        decoded_text = re.sub(r"'searched\?': (True|False)", r'"searched": \1', decoded_text)
        decoded_text = decoded_text.replace('True', 'true').replace('False', 'false')
        
        # íŒŒì‹± ì‹œë„
        try:
            data = json.loads(decoded_text)
        except json.JSONDecodeError as e:
            logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, ì •ê·œì‹ ë°©ì‹ ì‚¬ìš©: {e}")
            return extract_with_regex(data_text)
        
        movies = []
        
        # phrases ë°°ì—´ì—ì„œ ì˜í™” ì •ë³´ ì¶”ì¶œ
        if 'phrases' in data and data['phrases']:
            logger.info(f"phrases ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: {len(data['phrases'])}ê°œ")
            
            for i, phrase in enumerate(data['phrases']):
                try:
                    movie_info = extract_single_movie_info(phrase)
                    
                    if movie_info and validate_movie_info(movie_info):
                        # ìƒˆ ëª¨ë¸ êµ¬ì¡°ì— ë§ê²Œ í•„ë“œëª… ë§¤í•‘
                        normalized_movie = normalize_movie_info(movie_info)
                        movies.append(normalized_movie)
                        
                except Exception as e:
                    logger.error(f"ì˜í™” ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨ (ì¸ë±ìŠ¤ {i}): {e}")
                    continue
        else:
            logger.warning("phrases ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        # ìºì‹œì— ì €ì¥ (30ë¶„)
        if movies:
            cache.set(cache_key, movies, 1800)
        
        logger.info(f"ì˜í™” ì •ë³´ ì¶”ì¶œ ì™„ë£Œ: {len(movies)}ê°œ")
        return movies
        
    except Exception as e:
        logger.error(f"íŒŒì‹± ì˜¤ë¥˜: {e}")
        return extract_with_regex(data_text)


def extract_single_movie_info(phrase):
    """ë‹¨ì¼ phraseì—ì„œ ì˜í™” ì •ë³´ ì¶”ì¶œ"""
    movie_info = {}
    
    # video-infoì—ì„œ infoì™€ source_url ì¶”ì¶œ
    if 'video-info' in phrase and phrase['video-info']:
        video_info = phrase['video-info']
        info_text = video_info.get('info', '')
        
        # ì •ê·œ í‘œí˜„ì‹ìœ¼ë¡œ ì‹œê°„ ë¶€ë¶„ ì°¾ê¸°
        match = re.search(r'\[(\d{2}:\d{2}:\d{2})\]', info_text)
        
        if match:
            start_time = match.group(1)
            name = info_text.replace(f' [{start_time}]', '').strip()
        else:
            name = info_text.strip()
            start_time = "00:00:00"
        
        movie_info['start_time'] = start_time
        movie_info['name'] = name
        movie_info['source_url'] = video_info.get('source-url', '')
    
    # video-urlê³¼ text ì¶”ì¶œ
    movie_info['video_url'] = phrase.get('video-url', '')
    movie_info['text'] = phrase.get('text', '')
    
    return movie_info


def normalize_movie_info(movie_info):
    """ì¶”ì¶œëœ ì˜í™” ì •ë³´ë¥¼ ìƒˆ ëª¨ë¸ êµ¬ì¡°ì— ë§ê²Œ ì •ê·œí™”"""
    normalized = {}
    
    # ê¸°ë³¸ ì •ë³´ ë§¤í•‘
    normalized['raw_name'] = movie_info.get('name', '')
    normalized['dialogue_phrase'] = movie_info.get('text', '')
    normalized['dialogue_start_time'] = movie_info.get('start_time', '00:00:00')
    normalized['video_url'] = movie_info.get('video_url', '')
    normalized['source_url'] = movie_info.get('source_url', '')
    
    # ì˜í™” ì œëª© íŒŒì‹±
    parsed_movie = parse_movie_title(movie_info.get('name', ''))
    normalized.update(parsed_movie)
    
    # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
    normalized['data_source'] = 'playphrase.me'
    normalized['extraction_method'] = 'api_auto'
    normalized['raw_data'] = movie_info
    
    return normalized


def parse_movie_title(name):
    """ì˜í™” ì œëª© ë¬¸ìì—´ì—ì„œ ì˜í™” ì •ë³´ íŒŒì‹±"""
    movie_data = {
        'movie_title': name,
        'original_title': '',
        'release_year': '1004',
        'director': 'ahading',
        'production_country': 'ì§€êµ¬'
    }
    
    # ì—°ë„ ì¶”ì¶œ íŒ¨í„´ë“¤
    year_patterns = [
        r'\((\d{4})\)',  # (1999)
        r'\[(\d{4})\]',  # [1999]
        r'(\d{4})$',     # ëì— ë…„ë„
    ]
    
    for pattern in year_patterns:
        match = re.search(pattern, name)
        if match:
            year = match.group(1)
            movie_data['release_year'] = year
            movie_data['movie_title'] = re.sub(pattern, '', name).strip()
            break
    
    # ì œëª© ì •ë¦¬
    title = movie_data['movie_title'].strip()
    
    # ì¼ë°˜ì ì¸ êµ¬ë¶„ìë“¤ ì²˜ë¦¬
    separators = [' - ', ' | ', ' : ', ' / ']
    for sep in separators:
        if sep in title:
            parts = title.split(sep, 1)
            movie_data['movie_title'] = parts[0].strip()
            if len(parts) > 1:
                movie_data['original_title'] = parts[1].strip()
            break
    
    # ë¹ˆ ì œëª© ì²˜ë¦¬
    if not movie_data['movie_title']:
        movie_data['movie_title'] = name.strip() or 'Unknown Movie'
    
    return movie_data


def validate_movie_info(movie_info):
    """ì¶”ì¶œëœ ì˜í™” ì •ë³´ ìœ íš¨ì„± ê²€ì¦"""
    if not movie_info:
        return False
    
    # í•„ìˆ˜ í•„ë“œ í™•ì¸
    required_fields = ['name', 'text']
    for field in required_fields:
        if not movie_info.get(field, '').strip():
            logger.debug(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
            return False
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ ê²€ì¦
    text = movie_info.get('text', '')
    if len(text) < 2 or len(text) > 1000:
        logger.debug(f"í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶€ì ì ˆ: {len(text)}")
        return False
    
    # URL í˜•ì‹ ê²€ì¦
    video_url = movie_info.get('video_url', '')
    if video_url and not (video_url.startswith('http') or video_url.startswith('//')):
        logger.debug(f"ë¹„ë””ì˜¤ URL í˜•ì‹ ì˜¤ë¥˜: {video_url}")
        return False
    
    return True


def extract_with_regex(data_text):
    """ì •ê·œì‹ì„ ì‚¬ìš©í•œ ì§ì ‘ ì¶”ì¶œ (JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ëŒ€ì•ˆ)"""
    if not data_text:
        return []
    
    movies = []
    
    try:
        logger.info("ì •ê·œì‹ ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ ì‹œì‘")
        
        # ê° ì˜í™” í´ë¦½ ë¸”ë¡ì„ ì°¾ê¸°
        pattern = r"Â°'video-info'.*?(?=Â°'video-info'|$)"
        matches = re.findall(pattern, data_text, re.DOTALL)
        
        logger.info(f"ì •ê·œì‹ìœ¼ë¡œ {len(matches)}ê°œ ë¸”ë¡ ë°œê²¬")
        
        for i, match in enumerate(matches):
            try:
                movie_info = extract_single_movie_info_regex(match)
                
                if movie_info and validate_movie_info(movie_info):
                    normalized_movie = normalize_movie_info(movie_info)
                    movies.append(normalized_movie)
                    
            except Exception as e:
                logger.error(f"ì •ê·œì‹ ì¶”ì¶œ ì‹¤íŒ¨ (ë¸”ë¡ {i}): {e}")
                continue
    
    except Exception as e:
        logger.error(f"ì •ê·œì‹ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return []
    
    logger.info(f"ì •ê·œì‹ ì¶”ì¶œ ì™„ë£Œ: {len(movies)}ê°œ")
    return movies


def extract_single_movie_info_regex(match):
    """ì •ê·œì‹ì„ ì‚¬ìš©í•œ ë‹¨ì¼ ì˜í™” ì •ë³´ ì¶”ì¶œ"""
    movie_info = {}
    
    # info ì¶”ì¶œ
    info_match = re.search(r"'info':\s*'([^']*)'", match)
    if info_match:
        info_text = info_match.group(1)
        info_text = info_text.replace('Â¡', '[').replace('Â¿', ']')
        
        # ì‹œê°„ ì¶”ì¶œ
        time_match = re.search(r'\[(\d{2}:\d{2}:\d{2})\]', info_text)
        
        if time_match:
            start_time = time_match.group(1)
            name = info_text.replace(f' [{start_time}]', '').strip()
        else:
            start_time = "00:00:00"
            name = info_text.strip()
        
        movie_info['start_time'] = start_time
        movie_info['name'] = name
    
    # source_url ì¶”ì¶œ
    source_url_match = re.search(r"'source[-_]url':\s*'([^']*)'", match)
    if source_url_match:
        movie_info['source_url'] = source_url_match.group(1)
    
    # video-url ì¶”ì¶œ
    video_url_match = re.search(r"'video[-_]url':\s*'([^']*)'", match)
    if video_url_match:
        movie_info['video_url'] = video_url_match.group(1)
    
    # text ì¶”ì¶œ
    text_match = re.search(r"'text':\s*'([^']*)'", match)
    if text_match:
        text_content = text_match.group(1)
        text_content = text_content.replace('Â¡', '[').replace('Â¿', ']')
        movie_info['text'] = text_content
    
    return movie_info


# ===== 4ê°œ ëª¨ë“ˆ ì—°ë™ ìµœì í™” í•¨ìˆ˜ë“¤ =====

def check_existing_movies(movies_data):
    """
    DBì— ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì˜í™”ë“¤ í™•ì¸ (ìµœì í™”ëœ ë§¤ë‹ˆì € í™œìš©)
    
    ê°œì„ ì‚¬í•­:
    - get_movie_info.pyì˜ ì¤‘ë³µ ê²€ì‚¬ì™€ ì—°ë™
    - views.pyì˜ DB ìš°ì„  ì •ì±… ì§€ì›
    - ë°°ì¹˜ ìµœì í™”
    """
    if not movies_data:
        return [], []
    
    new_movies = []
    existing_movies = []
    
    # ì˜í™” ì œëª©ë“¤ì„ ë¯¸ë¦¬ ì¶”ì¶œí•˜ì—¬ ë°°ì¹˜ ì¡°íšŒ
    movie_lookup = {}
    
    for i, movie_data in enumerate(movies_data):
        movie_title = movie_data.get('movie_title', '')
        release_year = movie_data.get('release_year', '1004')
        director = movie_data.get('director', 'ahading')
        
        key = (movie_title, release_year, director)
        movie_lookup[key] = movie_data
    
    # ë°°ì¹˜ë¡œ ê¸°ì¡´ ì˜í™”ë“¤ ì¡°íšŒ (ì„±ëŠ¥ ìµœì í™”)
    if movie_lookup:
        title_list = [key[0] for key in movie_lookup.keys()]
        year_list = [key[1] for key in movie_lookup.keys()]
        director_list = [key[2] for key in movie_lookup.keys()]
        
        # ë§¤ë‹ˆì €ë¥¼ í™œìš©í•œ íš¨ìœ¨ì ì¸ ì¡°íšŒ
        existing_in_db = MovieTable.objects.filter(
            movie_title__in=title_list,
            release_year__in=year_list,
            director__in=director_list
        ).values('movie_title', 'release_year', 'director', 'id')
        
        # ê¸°ì¡´ ì˜í™” ë”•ì…”ë„ˆë¦¬ ìƒì„±
        existing_dict = {}
        for movie in existing_in_db:
            key = (movie['movie_title'], movie['release_year'], movie['director'])
            existing_dict[key] = movie['id']
    
    # ì‹ ê·œ/ê¸°ì¡´ ë¶„ë¥˜
    for key, movie_data in movie_lookup.items():
        if key in existing_dict:
            movie_data['existing_movie_id'] = existing_dict[key]
            existing_movies.append(movie_data)
        else:
            new_movies.append(movie_data)
    
    logger.info(f"ë°°ì¹˜ ì¤‘ë³µ ê²€ì‚¬ ì™„ë£Œ: ì‹ ê·œ {len(new_movies)}ê°œ, ê¸°ì¡´ {len(existing_movies)}ê°œ")
    
    return new_movies, existing_movies


def clean_data_from_playphrase(data_text, request_phrase=None, request_korean=None):
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - 4ê°œ ëª¨ë“ˆ ì™„ì „ ìµœì í™” íŒŒì´í”„ë¼ì¸
    
    ê°œì„ ì‚¬í•­:
    - get_movie_info.pyì™€ ì—°ë™í•œ ìŠ¤ë§ˆíŠ¸ ì²˜ë¦¬
    - views.pyì˜ ìš”ì²­ ì •ë³´ í™œìš©
    - RequestTable ë§¤ë‹ˆì € í™œìš©
    - ë‹¨ê³„ë³„ ì²˜ë¦¬ ìµœì í™”
    """
    logger.info("playphrase.me ë°ì´í„° ì •ë¦¬ ì‹œì‘ (4ê°œ ëª¨ë“ˆ ìµœì í™”)")
    
    # 0ë‹¨ê³„: ìš”ì²­ ì •ë³´ ì²˜ë¦¬ (views.py ì—°ë™)
    if request_phrase:
        logger.info(f"ìš”ì²­êµ¬ë¬¸ ì •ë³´ í™œìš©: '{request_phrase}' (í•œê¸€: '{request_korean}')")
        
        # RequestTableì— ì‚¬ì „ ê¸°ë¡ (ë§¤ë‹ˆì € í™œìš©)
        try:
            request_obj, created = RequestTable.objects.get_or_create(
                request_phrase=request_phrase,
                defaults={
                    'request_korean': request_korean,
                    'search_count': 1,
                    'result_count': 0,  # ì„ì‹œê°’
                }
            )
            if not created:
                RequestTable.objects.increment_search_count(request_phrase)
        except Exception as e:
            logger.warning(f"ìš”ì²­ ê¸°ë¡ ì‹¤íŒ¨: {e}")
    
    # 1ë‹¨ê³„: ê¸°ë³¸ ì¶”ì¶œ (ìºì‹± ìš°ì„ )
    movies = extract_movie_info(data_text)
    if not movies:
        logger.warning("ì˜í™” ì •ë³´ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []
    
    # 2ë‹¨ê³„: ë°°ì¹˜ ì¤‘ë³µ ê²€ì‚¬ (ìµœì í™”ëœ ë§¤ë‹ˆì € í™œìš©)
    new_movies, existing_movies = check_existing_movies(movies)
    
    # 3ë‹¨ê³„: ì‹ ê·œ ì˜í™” ë°ì´í„° ë³´ê°• (ì¡°ê±´ë¶€)
    if new_movies:
        logger.info(f"ì‹ ê·œ ì˜í™” {len(new_movies)}ê°œ ë°ì´í„° ë³´ê°• ì‹œì‘")
        new_movies = enrich_movie_data_smart(new_movies)
    
    # 4ë‹¨ê³„: ê¸°ì¡´ ì˜í™” ëŒ€ì‚¬ ì¶”ê°€ ì²˜ë¦¬
    if existing_movies:
        logger.info(f"ê¸°ì¡´ ì˜í™” {len(existing_movies)}ê°œì— ìƒˆ ëŒ€ì‚¬ ì¶”ê°€")
        existing_movies = process_existing_movies_dialogues(existing_movies)
    
    # 5ë‹¨ê³„: ê²°ê³¼ í†µí•© ë° í’ˆì§ˆ ê²€ì¦
    all_movies = new_movies + existing_movies
    validated_movies = validate_and_enhance_movies(all_movies)
    
    # 6ë‹¨ê³„: RequestTable ê²°ê³¼ ìˆ˜ ì—…ë°ì´íŠ¸
    if request_phrase:
        try:
            RequestTable.objects.filter(request_phrase=request_phrase).update(
                result_count=len(validated_movies)
            )
        except Exception as e:
            logger.warning(f"ê²°ê³¼ ìˆ˜ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    logger.info(f"ë°ì´í„° ì •ë¦¬ ì™„ë£Œ: ì „ì²´ {len(validated_movies)}ê°œ (ì‹ ê·œ {len(new_movies)}ê°œ, ê¸°ì¡´ {len(existing_movies)}ê°œ)")
    
    return validated_movies


def enrich_movie_data_smart(movies_data):
    """ì˜í™” ë°ì´í„° ìŠ¤ë§ˆíŠ¸ ë³´ê°• (get_movie_info.py ì—°ë™)"""
    enriched_movies = []
    
    for movie_data in movies_data:
        try:
            # ê¸°ë³¸ ë°ì´í„° í’ˆì§ˆ í‰ê°€
            initial_quality = evaluate_data_quality(movie_data)
            
            # í’ˆì§ˆì´ ë‚®ì€ ê²½ìš°ë§Œ IMDB ì¡°íšŒ (API ì ˆì•½)
            if initial_quality in ['incomplete', 'error']:
                movie_title = movie_data.get('movie_title', '')
                release_year = movie_data.get('release_year', '')
                
                # ìºì‹œ ìš°ì„  IMDB ì •ë³´ ì¡°íšŒ
                imdb_data = get_cached_imdb_info(movie_title, release_year)
                if imdb_data:
                    movie_data.update(imdb_data)
            
            # ìµœì¢… í’ˆì§ˆ í‰ê°€
            movie_data['data_quality'] = evaluate_data_quality(movie_data)
            enriched_movies.append(movie_data)
            
        except Exception as e:
            logger.error(f"ì˜í™” ë°ì´í„° ë³´ê°• ì‹¤íŒ¨: {e}")
            enriched_movies.append(movie_data)  # ì‹¤íŒ¨í•´ë„ ì›ë³¸ ë³´ì¡´
    
    return enriched_movies


def process_existing_movies_dialogues(existing_movies):
    """ê¸°ì¡´ ì˜í™”ì— ìƒˆ ëŒ€ì‚¬ ì¶”ê°€ ì²˜ë¦¬"""
    processed_movies = []
    
    for movie_data in existing_movies:
        try:
            movie_id = movie_data.get('existing_movie_id')
            dialogue_phrase = movie_data.get('dialogue_phrase', '')
            
            if movie_id and dialogue_phrase:
                # ë™ì¼í•œ ëŒ€ì‚¬ê°€ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸ (ë§¤ë‹ˆì € í™œìš©)
                existing_dialogue = DialogueTable.objects.filter(
                    movie_id=movie_id,
                    dialogue_phrase=dialogue_phrase
                ).first()
                
                if not existing_dialogue:
                    # ìƒˆ ëŒ€ì‚¬ ì¶”ê°€ í‘œì‹œ
                    movie_data['is_new_dialogue'] = True
                else:
                    # ê¸°ì¡´ ëŒ€ì‚¬ ì—…ë°ì´íŠ¸ (ì¡°íšŒìˆ˜ ë“±)
                    movie_data['is_new_dialogue'] = False
                    movie_data['existing_dialogue_id'] = existing_dialogue.id
                
                processed_movies.append(movie_data)
                
        except Exception as e:
            logger.error(f"ê¸°ì¡´ ì˜í™” ëŒ€ì‚¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            processed_movies.append(movie_data)
    
    return processed_movies


def get_cached_imdb_info(movie_title, release_year):
    """ìºì‹œ ìš°ì„  IMDB ì •ë³´ ì¡°íšŒ"""
    imdb_cache_key = f"imdb_{movie_title}_{release_year}"
    cached_imdb = cache.get(imdb_cache_key)
    
    if cached_imdb:
        return cached_imdb
    
    # ìƒˆë¡œ ì¡°íšŒ
    try:
        poster_url = get_poster_url(movie_title, release_year)
        imdb_data = {}
        
        if poster_url:
            imdb_data['poster_url'] = poster_url
            
            # í¬ìŠ¤í„° ë‹¤ìš´ë¡œë“œ (ì„ íƒì )
            poster_path = download_poster_image(poster_url, movie_title)
            if poster_path:
                imdb_data['poster_image_path'] = poster_path
        
        # ìºì‹œì— ì €ì¥ (24ì‹œê°„)
        if imdb_data:
            cache.set(imdb_cache_key, imdb_data, 86400)
        
        return imdb_data
        
    except Exception as e:
        logger.warning(f"IMDB ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ ({movie_title}): {e}")
        return {}


def validate_and_enhance_movies(movies_data):
    """ì˜í™” ë°ì´í„° ìµœì¢… ê²€ì¦ ë° ê°•í™”"""
    validated_movies = []
    
    for movie_data in movies_data:
        try:
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            if not movie_data.get('movie_title') or not movie_data.get('dialogue_phrase'):
                logger.warning(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½, ê±´ë„ˆëœ€: {movie_data}")
                continue
            
            # ë©”íƒ€ë°ì´í„° ê°•í™”
            movie_data['processed_at'] = timezone.now().isoformat()
            movie_data['processing_version'] = '4.0'  # 4ê°œ ëª¨ë“ˆ ìµœì í™” ë²„ì „
            
            # views.py ì—°ë™ì„ ìœ„í•œ ì¶”ê°€ ì •ë³´
            movie_data['from_cache'] = False
            movie_data['source'] = 'playphrase_api'
            
            validated_movies.append(movie_data)
            
        except Exception as e:
            logger.error(f"ì˜í™” ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {e}")
            continue
    
    return validated_movies


def evaluate_data_quality(movie_data):
    """
    ì˜í™” ë°ì´í„° í’ˆì§ˆ í‰ê°€
    Returns: 'verified', 'pending', 'incomplete', 'error'
    """
    score = 0
    
    # ê¸°ë³¸ ì •ë³´ ì²´í¬
    if movie_data.get('movie_title'):
        score += 20
    if movie_data.get('release_year') and movie_data['release_year'] != '1004':
        score += 20
    if movie_data.get('dialogue_phrase'):
        score += 20
    if movie_data.get('video_url'):
        score += 20
    if movie_data.get('poster_url'):
        score += 10
    if movie_data.get('director') and movie_data['director'] != 'ahading':
        score += 10
    
    # í’ˆì§ˆ ë“±ê¸‰ ê²°ì •
    if score >= 80:
        return 'verified'
    elif score >= 60:
        return 'pending'
    elif score >= 40:
        return 'incomplete'
    else:
        return 'error'


# ===== 4ê°œ ëª¨ë“ˆ ì—°ë™ í•¨ìˆ˜ë“¤ =====

def integrate_with_get_movie_info(text):
    """get_movie_info.pyì™€ì˜ ì—°ë™ í•¨ìˆ˜"""
    try:
        from phrase.application.get_movie_info import check_existing_database_data
        
        if check_existing_database_data(text):
            logger.info(f"get_movie_infoì™€ ì—°ë™: DBì— ê¸°ì¡´ ë°ì´í„° ì¡´ì¬ - {text}")
            return None  # API í˜¸ì¶œ ë¶ˆí•„ìš”
        
        return True  # API í˜¸ì¶œ í•„ìš”
        
    except ImportError:
        logger.warning("get_movie_info ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨")
        return True


def integrate_with_views_context(movies_data):
    """views.pyì˜ context í˜•ì‹ê³¼ ì—°ë™"""
    if not movies_data:
        return []
    
    # views.pyì™€ ë™ì¼í•œ êµ¬ì¡°ë¡œ ë³€í™˜
    movies_context = []
    
    for movie_data in movies_data:
        context_movie = {
            'title': movie_data.get('movie_title', ''),
            'original_title': movie_data.get('original_title', ''),
            'year': movie_data.get('release_year', '1004'),
            'country': movie_data.get('production_country', 'ì§€êµ¬'),
            'director': movie_data.get('director', 'ahading'),
            'genre': movie_data.get('genre', ''),
            'imdb_rating': movie_data.get('imdb_rating'),
            'imdb_url': movie_data.get('imdb_url', ''),
            'poster_url': movie_data.get('poster_url', ''),
            'poster_image_path': movie_data.get('poster_image_path', ''),
            'data_quality': movie_data.get('data_quality', 'pending'),
            'view_count': 0,  # ì‹ ê·œ ì˜í™”
            'like_count': 0,  # ì‹ ê·œ ì˜í™”
            'dialogues': [{
                'id': None,  # DB ì €ì¥ í›„ ì„¤ì •
                'text': movie_data.get('dialogue_phrase', ''),
                'text_ko': '',  # ë²ˆì—­ì€ ë‚˜ì¤‘ì—
                'text_ja': '',
                'text_zh': '',
                'start_time': movie_data.get('dialogue_start_time', '00:00:00'),
                'end_time': '',
                'duration_seconds': None,
                'duration_display': 'ì•Œ ìˆ˜ ì—†ìŒ',
                'video_url': movie_data.get('video_url', ''),
                'video_file_path': '',
                'video_quality': 'unknown',
                'file_size_bytes': None,
                'translation_method': 'unknown',
                'translation_quality': 'fair',
                'play_count': 0,
                'like_count': 0,
                'created_at': timezone.now().isoformat(),
            }],
            'dialogue_count': 1
        }
        
        movies_context.append(context_movie)
    
    logger.info(f"views.py context í˜•ì‹ ë³€í™˜ ì™„ë£Œ: {len(movies_context)}ê°œ")
    return movies_context


def integrate_with_managers_statistics(movies_data):
    """managers.py í†µê³„ì™€ ì—°ë™"""
    try:
        # ì˜í™” ë§¤ë‹ˆì € í†µê³„ ì—…ë°ì´íŠ¸
        movie_stats = MovieTable.objects.get_statistics()
        dialogue_stats = DialogueTable.objects.get_statistics()
        
        processing_stats = {
            'new_movies_processed': len([m for m in movies_data if not m.get('existing_movie_id')]),
            'existing_movies_updated': len([m for m in movies_data if m.get('existing_movie_id')]),
            'total_dialogues_added': len(movies_data),
            'data_quality_distribution': {},
        }
        
        # í’ˆì§ˆ ë¶„í¬ ê³„ì‚°
        for movie in movies_data:
            quality = movie.get('data_quality', 'unknown')
            processing_stats['data_quality_distribution'][quality] = \
                processing_stats['data_quality_distribution'].get(quality, 0) + 1
        
        logger.info(f"ë§¤ë‹ˆì € í†µê³„ ì—°ë™ ì™„ë£Œ: {processing_stats}")
        return processing_stats
        
    except Exception as e:
        logger.error(f"ë§¤ë‹ˆì € í†µê³„ ì—°ë™ ì‹¤íŒ¨: {e}")
        return {}


def test_four_modules_integration():
    """4ê°œ ëª¨ë“ˆ ì—°ë™ í…ŒìŠ¤íŠ¸"""
    test_results = {
        'models_integration': False,
        'managers_integration': False,
        'views_integration': False,
        'get_movie_info_integration': False,
    }
    
    try:
        # models.py ì—°ë™ í…ŒìŠ¤íŠ¸
        test_movie = MovieTable.objects.first()
        if test_movie:
            test_results['models_integration'] = True
        
        # managers.py ì—°ë™ í…ŒìŠ¤íŠ¸
        stats = MovieTable.objects.get_statistics()
        if stats:
            test_results['managers_integration'] = True
        
        # views.py ì—°ë™ í…ŒìŠ¤íŠ¸ (í•¨ìˆ˜ ì¡´ì¬ í™•ì¸)
        from phrase import views
        if hasattr(views, 'build_movies_context_from_db'):
            test_results['views_integration'] = True
        
        # get_movie_info.py ì—°ë™ í…ŒìŠ¤íŠ¸
        from phrase.application import get_movie_info
        if hasattr(get_movie_info, 'check_existing_database_data'):
            test_results['get_movie_info_integration'] = True
        
    except Exception as e:
        logger.error(f"ëª¨ë“ˆ ì—°ë™ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    logger.info(f"4ê°œ ëª¨ë“ˆ ì—°ë™ í…ŒìŠ¤íŠ¸ ê²°ê³¼: {test_results}")
    return test_results


# ===== ì„±ëŠ¥ ìµœì í™” ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ =====

def batch_process_movies_optimized(movies_data, batch_size=50):
    """
    ì˜í™” ë°ì´í„° ìµœì í™”ëœ ë°°ì¹˜ ì²˜ë¦¬
    - 4ê°œ ëª¨ë“ˆ ì—°ë™ ìµœì í™”
    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ 
    - ì—ëŸ¬ ë³µêµ¬ ê°•í™”
    """
    if not movies_data:
        return []
    
    total_batches = (len(movies_data) + batch_size - 1) // batch_size
    processed_movies = []
    
    logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(movies_data)}ê°œ ë°ì´í„°, {total_batches}ê°œ ë°°ì¹˜")
    
    for i in range(0, len(movies_data), batch_size):
        batch = movies_data[i:i + batch_size]
        batch_num = (i // batch_size) + 1
        
        logger.info(f"ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘: {len(batch)}ê°œ")
        
        try:
            # ë°°ì¹˜ë³„ íŠ¸ëœì­ì…˜ ì²˜ë¦¬
            with transaction.atomic():
                batch_processed = []
                
                for movie_data in batch:
                    try:
                        # ë°ì´í„° ì •ê·œí™”
                        normalized_movie = normalize_movie_info(movie_data)
                        
                        # ìœ íš¨ì„± ê²€ì¦
                        if validate_movie_info(normalized_movie):
                            # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
                            normalized_movie['batch_number'] = batch_num
                            normalized_movie['processing_timestamp'] = timezone.now().isoformat()
                            
                            batch_processed.append(normalized_movie)
                        else:
                            logger.warning(f"ìœ íš¨ì„± ê²€ì¦ ì‹¤íŒ¨: {movie_data.get('movie_title', 'Unknown')}")
                            
                    except Exception as e:
                        logger.error(f"ê°œë³„ ì˜í™” ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        continue
                
                processed_movies.extend(batch_processed)
                
                # ë°°ì¹˜ ì™„ë£Œ ë¡œê¹…
                logger.info(f"ë°°ì¹˜ {batch_num} ì™„ë£Œ: {len(batch_processed)}ê°œ ì„±ê³µ")
                
        except Exception as e:
            logger.error(f"ë°°ì¹˜ {batch_num} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # ë°°ì¹˜ ì‹¤íŒ¨ ì‹œì—ë„ ê³„ì† ì§„í–‰
            continue
            
        # ë©”ëª¨ë¦¬ ê´€ë¦¬ (ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì‹œ)
        if len(processed_movies) > 1000:
            logger.info(f"ë©”ëª¨ë¦¬ ê´€ë¦¬: ì¤‘ê°„ ê²°ê³¼ {len(processed_movies)}ê°œ ì²˜ë¦¬ ì™„ë£Œ")
    
    logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {len(processed_movies)}ê°œ ì„±ê³µ")
    return processed_movies


def optimize_cache_strategy():
    """ìºì‹œ ì „ëµ ìµœì í™”"""
    try:
        # ìì£¼ ì‚¬ìš©ë˜ëŠ” ì˜í™” ì •ë³´ ì‚¬ì „ ìºì‹±
        popular_movies = MovieTable.objects.popular(20)
        
        for movie in popular_movies:
            cache_key = f"movie_info_{movie.movie_title}_{movie.release_year}"
            movie_data = {
                'id': movie.id,
                'title': movie.movie_title,
                'year': movie.release_year,
                'director': movie.director,
            }
            cache.set(cache_key, movie_data, 3600)  # 1ì‹œê°„
        
        logger.info(f"ì¸ê¸° ì˜í™” {len(popular_movies)}ê°œ ì‚¬ì „ ìºì‹± ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"ìºì‹œ ìµœì í™” ì‹¤íŒ¨: {e}")


def create_legacy_compatibility_format(movies_data):
    """ê¸°ì¡´ clean_data_from_playphrase í˜¸ì¶œê³¼ì˜ í˜¸í™˜ì„± ìœ ì§€"""
    legacy_movies = []
    
    for movie_data in movies_data:
        legacy_movie = {
            # ê¸°ì¡´ í•„ë“œë“¤
            'name': movie_data.get('raw_name', movie_data.get('movie_title', '')),
            'text': movie_data.get('dialogue_phrase', ''),
            'start_time': movie_data.get('dialogue_start_time', '00:00:00'),
            'video_url': movie_data.get('video_url', ''),
            'source_url': movie_data.get('source_url', ''),
            
            # ìƒˆ í•„ë“œë“¤
            'movie_title': movie_data.get('movie_title', ''),
            'release_year': movie_data.get('release_year', '1004'),
            'director': movie_data.get('director', 'ahading'),
            'data_quality': movie_data.get('data_quality', 'pending'),
        }
        
        legacy_movies.append(legacy_movie)
    
    return legacy_movies


def print_movies(movies):
    """ì¶”ì¶œëœ ì˜í™” ì •ë³´ë¥¼ ì½˜ì†”ì— ì¶œë ¥"""
    if not movies:
        logger.info("ì¶œë ¥í•  ì˜í™” ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    logger.info(f"\n=== ì´ {len(movies)}ê°œì˜ ì˜í™” ì •ë³´ ì¶”ì¶œ ===\n")
    
    for i, movie in enumerate(movies, 1):
        print(f"[{i}] {movie.get('movie_title', 'N/A')} ({movie.get('release_year', 'N/A')})")
        print(f"    ê°ë…: {movie.get('director', 'N/A')}")
        print(f"    ëŒ€ì‚¬: {movie.get('dialogue_phrase', 'N/A')}")
        print(f"    ì‹œì‘ì‹œê°„: {movie.get('dialogue_start_time', 'N/A')}")
        print(f"    ë¹„ë””ì˜¤ URL: {movie.get('video_url', 'N/A')}")
        print(f"    ë°ì´í„° í’ˆì§ˆ: {movie.get('data_quality', 'N/A')}")
        print("-" * 80)


# ===== í†µê³„ ë° ë¶„ì„ í•¨ìˆ˜ë“¤ =====

def get_extraction_statistics():
    """ì¶”ì¶œ í†µê³„ ì¡°íšŒ (managers.py í†µê³„ì™€ ì—°ë™)"""
    cache_key = 'extraction_statistics_v4'
    stats = cache.get(cache_key)
    
    if stats is None:
        try:
            # managers.py í†µê³„ í™œìš©
            movie_stats = MovieTable.objects.get_statistics()
            dialogue_stats = DialogueTable.objects.get_statistics()
            
            stats = {
                'total_extracted': movie_stats.get('total_movies', 0),
                'successful_extractions': movie_stats.get('active_movies', 0),
                'failed_extractions': movie_stats.get('total_movies', 0) - movie_stats.get('active_movies', 0),
                'average_dialogues_per_movie': round(
                    dialogue_stats.get('total_dialogues', 0) / max(movie_stats.get('total_movies', 1), 1), 2
                ),
                'data_quality_distribution': {
                    'verified': movie_stats.get('by_quality', {}).get('verified', 0),
                    'pending': movie_stats.get('by_quality', {}).get('pending', 0),
                },
                'translation_rate': dialogue_stats.get('translation_rate', 0),
                'last_updated': timezone.now().isoformat()
            }
            
            # ìºì‹œì— ì €ì¥ (10ë¶„)
            cache.set(cache_key, stats, 600)
            
        except Exception as e:
            logger.error(f"í†µê³„ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            stats = {'error': str(e)}
    
    return stats


def get_four_modules_status():
    """4ê°œ ëª¨ë“ˆ ìƒíƒœ ì¢…í•© ì¡°íšŒ"""
    try:
        status = {
            'models_status': {
                'total_movies': MovieTable.objects.count(),
                'total_dialogues': DialogueTable.objects.count(),
                'total_requests': RequestTable.objects.count(),
            },
            'managers_status': {
                'cache_enabled': True,
                'statistics_available': True,
            },
            'views_status': {
                'db_first_policy': True,
                'caching_enabled': True,
            },
            'get_movie_info_status': {
                'api_client_ready': True,
                'db_check_enabled': True,
            },
            'clean_data_status': {
                'version': '4.0',
                'integration_complete': True,
                'performance_optimized': True,
            }
        }
        
        # ì—°ë™ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
        integration_test = test_four_modules_integration()
        status['integration_test'] = integration_test
        
        return status
        
    except Exception as e:
        logger.error(f"ëª¨ë“ˆ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {'error': str(e)}


def cleanup_and_finalize():
    """ì²˜ë¦¬ ì™„ë£Œ í›„ ì •ë¦¬ ì‘ì—…"""
    try:
        # í†µê³„ ì—…ë°ì´íŠ¸
        processing_stats = get_extraction_statistics()
        logger.info(f"ìµœì¢… ì²˜ë¦¬ í†µê³„: {processing_stats}")
        
        # ì„±ëŠ¥ ìµœì í™” ì ìš©
        optimize_cache_strategy()
        
        logger.info("clean_data.py ì •ë¦¬ ì‘ì—… ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"ì •ë¦¬ ì‘ì—… ì¤‘ ì˜¤ë¥˜: {e}")


# ===== ëª¨ë“ˆ ì´ˆê¸°í™” ë° ì„¤ì • =====

def initialize_clean_data_module():
    """clean_data ëª¨ë“ˆ ì´ˆê¸°í™”"""
    try:
        # 4ê°œ ëª¨ë“ˆ ì—°ë™ í™•ì¸
        integration_status = test_four_modules_integration()
        
        if all(integration_status.values()):
            logger.info("âœ… clean_data.py ì´ˆê¸°í™” ì„±ê³µ: 4ê°œ ëª¨ë“ˆ ì™„ì „ ì—°ë™")
        else:
            logger.warning(f"âš ï¸ ì¼ë¶€ ëª¨ë“ˆ ì—°ë™ ì‹¤íŒ¨: {integration_status}")
        
        # ì„±ëŠ¥ ìµœì í™” ì ìš©
        optimize_cache_strategy()
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ clean_data.py ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False


# ===== ì§„ì…ì  í•¨ìˆ˜ë“¤ =====

def clean_data_v4(data_text, request_phrase=None, request_korean=None, **kwargs):
    """
    clean_data.py v4.0 ë©”ì¸ ì§„ì…ì  (ê¶Œì¥)
    - 4ê°œ ëª¨ë“ˆ ì™„ì „ ìµœì í™”
    - ëª¨ë“  ìƒˆ ê¸°ëŠ¥ ì§€ì›
    """
    return clean_data_from_playphrase(data_text, request_phrase, request_korean)


def clean_data_from_playphrase_legacy(data_text):
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë ˆê±°ì‹œ í•¨ìˆ˜"""
    return clean_data_from_playphrase(data_text)


# ===== ë ˆê±°ì‹œ í˜¸í™˜ì„± ë³„ì¹­ë“¤ =====
extract_movie_info_legacy = extract_movie_info

# ===== ëª¨ë“ˆ ì´ˆê¸°í™” ì‹¤í–‰ =====
module_initialized = initialize_clean_data_module()

# ===== ìµœì¢… ë¡œê¹… ë° ë©”íƒ€ë°ì´í„° =====
logger.info(f"""
=== clean_data.py v4.0 ì´ˆê¸°í™” ì™„ë£Œ ===
ğŸ“± models.py ì—°ë™: âœ… ìµœì í™”ëœ ëª¨ë¸ í™œìš©
ğŸ”§ managers.py ì—°ë™: âœ… ì»¤ìŠ¤í…€ ë§¤ë‹ˆì € í™œìš©  
ğŸŒ views.py ì—°ë™: âœ… DB ìš°ì„  ì •ì±… ì§€ì›
ğŸ”— get_movie_info.py ì—°ë™: âœ… API ìµœì í™”
ğŸš€ ì„±ëŠ¥ ìµœì í™”: âœ… ìºì‹±, ë°°ì¹˜ì²˜ë¦¬, íŠ¸ëœì­ì…˜
ğŸ”„ í˜¸í™˜ì„±: âœ… ë ˆê±°ì‹œ ì§€ì› ìœ ì§€
ğŸ“Š í†µê³„ ì—°ë™: âœ… ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
ì´ˆê¸°í™” ìƒíƒœ: {'ì„±ê³µ' if module_initialized else 'ì‹¤íŒ¨'}
""")

# ëª¨ë“ˆ ë©”íƒ€ë°ì´í„°
__version__ = "4.0.0"
__compatibility__ = ["models.py", "managers.py", "views.py", "get_movie_info.py"]
__features__ = [
    "4ê°œ ëª¨ë“ˆ ì™„ì „ ì—°ë™",
    "DB ìš°ì„  ì •ì±… ì§€ì›", 
    "ìµœì í™”ëœ ë°°ì¹˜ ì²˜ë¦¬",
    "ìŠ¤ë§ˆíŠ¸ ìºì‹± ì „ëµ",
    "ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§",
    "ë ˆê±°ì‹œ í˜¸í™˜ì„± ìœ ì§€"
]
__author__ = "AI Assistant"
__description__ = "playphrase.me ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ì™„ì „ ìµœì í™”ëœ ëª¨ë“ˆ"